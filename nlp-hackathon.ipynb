{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-15T20:33:27.089342Z","iopub.status.busy":"2023-04-15T20:33:27.088930Z","iopub.status.idle":"2023-04-15T20:34:36.871835Z","shell.execute_reply":"2023-04-15T20:34:36.869268Z","shell.execute_reply.started":"2023-04-15T20:33:27.089307Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from xgboost import XGBClassifier\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV\n","from sklearn.metrics import roc_auc_score\n","\n","# Load the training data\n","train_data = pd.read_csv('/kaggle/input/hackathon/beginner_training.csv')\n","\n","# Preprocess the text data\n","train_data['clean_text_stopwordsremoved'] = train_data['clean_text_stopwordsremoved'].fillna('')\n","train_data['viral'] = train_data['viral'].apply(lambda x: 1 if x == 1 else 0)\n","\n","# Separate input features and target variable\n","X = train_data[['clean_text_stopwordsremoved', 'month', 'day_of_week', 'hour_of_day', 'display_text_range', 'is_quote_status', 'includes_media', 'number_hashtags', 'sentiment_fulltext', 'sentiment_cleantext']]\n","y = train_data['viral']\n","\n","# Split the data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Preprocess and vectorize text and categorical features\n","text_features = 'clean_text_stopwordsremoved'\n","categorical_features = ['month', 'day_of_week', 'hour_of_day', 'is_quote_status', 'includes_media']\n","numerical_features = ['display_text_range', 'number_hashtags', 'sentiment_fulltext', 'sentiment_cleantext']\n","\n","text_transformer = Pipeline([\n","    ('tfidf', TfidfVectorizer(stop_words='english'))\n","])\n","\n","categorical_transformer = Pipeline([\n","    ('onehot', OneHotEncoder())\n","])\n","\n","numerical_transformer = Pipeline([\n","    ('scaler', StandardScaler())\n","])\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('text', text_transformer, text_features),\n","        ('cat', categorical_transformer, categorical_features),\n","        ('num', numerical_transformer, numerical_features)\n","    ])\n","\n","# Update the model to use XGBoost classifier with some initial parameters\n","model = Pipeline([\n","    ('preprocessor', preprocessor),\n","    ('classifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss'))\n","])\n","\n","# Define the hyperparameter search space\n","param_dist = {\n","    'classifier__n_estimators': [100, 200],\n","    'classifier__learning_rate': [0.01, 0.1],\n","    'classifier__max_depth': [3, 5],\n","    'classifier__min_child_weight': [1, 5],\n","}\n","\n","# Perform a RandomizedSearch for the best hyperparameters\n","random_search = RandomizedSearchCV(model, param_dist, scoring='roc_auc', cv=5, n_iter=10, random_state=42, n_jobs=-1)\n","random_search.fit(X_train, y_train)\n","print(\"Best parameters found: \", random_search.best_params_)\n","print(\"Best score found: \", random_search.best_score_)\n","\n","# Train the model with the best parameters\n","best_model = random_search.best_estimator_\n","\n","# Make predictions on the validation set\n","y_val_pred_proba = best_model.predict_proba(X_val)[:, 1]\n","\n","# Evaluate the performance of the model on the validation set\n","val_auc = roc_auc_score(y_val, y_val_pred_proba)\n","print(f'Validation AUC: {val_auc}')\n","\n","# Load the test data\n","test_data = pd.read_csv('/kaggle/input/hackathon/beginner_testing.csv')\n","\n","# Preprocess the text data\n","test_data['clean_text_stopwordsremoved'] = test_data['clean_text_stopwordsremoved'].fillna('')\n","\n","# Preprocess and vectorize test data features\n","X_test = test_data[['clean_text_stopwordsremoved', 'month', 'day_of_week', 'hour_of_day', 'display_text_range', 'is_quote_status', 'includes_media', 'number_hashtags', 'sentiment_fulltext', 'sentiment_cleantext']]\n","\n","# Make predictions on the test data\n","y_test_pred_proba = best_model.predict_proba(X_test)[:, 1]\n","\n","# Create a submission file with viral value between 0 and 1\n","submission_df = pd.DataFrame({'tweet_id': test_data['tweet_id'], 'viral': y_test_pred_proba})\n","submission_df.to_csv('submission20.csv', index=False)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
